---
name: proof-report
description: Generate proof of work document for PR submission
argument-hint: [issue-number]
allowed-tools:
  - Read
  - Write
  - Bash
  - Grep
  - Glob
  - AskUserQuestion
---

<objective>
Generate a `.dev/<ISSUE_NUMBER>_PROOF_REPORT.md` document that serves as proof of work for PR submission.

Use this skill when:

- Completing a feature or bug fix
- Preparing to submit a PR
- After running `/ready` checklist
- User asks to "document the work" or "create proof"

The proof report captures test results, API verification, and implementation summary for the PR description.
</objective>

<context>
Issue number: $ARGUMENTS

Report location: `.dev/<ISSUE_NUMBER>_PROOF_REPORT.md`
Pattern is gitignored, so reports won't be committed.

From [CLAUDE.md](CLAUDE.md): "After completing work, create `.dev/{issue}_PROOF_REPORT.md`"
</context>

<process>

## Step 1: Determine Issue Number

If `$ARGUMENTS` provided, use it. Otherwise detect from branch name:

```bash
# Try to detect from branch name (e.g., fix/1234-description)
ISSUE_NUM=$(git branch --show-current | grep -oE '[0-9]+' | head -1)
```

If still unclear, ask:

```
AskUserQuestion(
  header: "Issue Number",
  question: "What is the GitHub issue number for this work?",
  options: [
    { label: "From branch", description: "Use: #${ISSUE_NUM}" }
  ]
)
```

Set the report path:

```bash
REPORT_PATH=".dev/${ISSUE_NUM}_PROOF_REPORT.md"
```

## Step 2: Gather Test Results

**Find related acceptance tests:**

```bash
# Search for tests related to the changes
TESTS=$(git diff --name-only HEAD~5 | grep "_test.go" | head -5)
```

**Get recent test output (if available):**

```bash
# Check if tests were run recently
if [ -f /tmp/testacc.log ]; then
  RECENT_OUTPUT=$(tail -50 /tmp/testacc.log)
fi
```

**Ask about test status:**

```
AskUserQuestion(
  header: "Test Results",
  question: "What were the acceptance test results?",
  options: [
    { label: "All passed", description: "All tests passed successfully" },
    { label: "Partial", description: "Some tests passed, need to note exceptions" },
    { label: "Not run", description: "Tests not run yet" }
  ]
)
```

If "Partial", ask for details about which tests and why.

## Step 3: Gather API Verification

**Check for mitmproxy logs:**

```bash
if [ -f /tmp/api_debug.log ]; then
  API_LOG_EXISTS=true
  # Extract relevant API calls
  API_CALLS=$(grep -E "GET|POST|PUT|DELETE" /tmp/api_debug.log | grep "api2/json" | head -10)
fi
```

**Ask about API verification:**

```
AskUserQuestion(
  header: "API Verification",
  question: "Was API behavior verified with mitmproxy?",
  options: [
    { label: "Yes, verified", description: "API calls confirmed correct" },
    { label: "Not applicable", description: "No API changes in this work" },
    { label: "Not done", description: "Need to run /debug-api first" }
  ]
)
```

If "Not done", suggest running `/debug-api` first.

## Step 4: Gather Implementation Summary

**Get changed files:**

```bash
CHANGED_FILES=$(git diff --name-only HEAD~5 | grep -E "\.go$" | head -20)
```

**Get commit history:**

```bash
COMMITS=$(git log --oneline HEAD~5..HEAD | head -10)
```

**Ask for summary:**

```
AskUserQuestion(
  header: "Summary",
  question: "Briefly describe what was implemented/fixed:",
  options: []
)
```

## Step 5: Generate Report

Create the report file:

```markdown
# Issue #${ISSUE_NUM} - Proof of Work Report

**Date:** $(date +%Y-%m-%d)
**GitHub Issue:** https://github.com/bpg/terraform-provider-proxmox/issues/${ISSUE_NUM}
**Author:** Claude Code

---

## Summary

${USER_SUMMARY}

## Files Changed

${CHANGED_FILES_LIST}

## Commits

${COMMITS_LIST}

## Test Results

### Acceptance Tests

| Test Name | Status |
|-----------|--------|
${TEST_TABLE}

### Test Output

\`\`\`
${TEST_OUTPUT_SNIPPET}
\`\`\`

## API Verification

${API_VERIFICATION_SECTION}

### Verified API Calls

\`\`\`
${API_CALLS_SNIPPET}
\`\`\`

## Checklist

- [x] `make build` passes
- [x] `make lint` shows 0 issues
- [x] `make test` passes
- [x] Acceptance tests pass
- [${API_CHECK}] API calls verified with mitmproxy
- [${DOCS_CHECK}] Documentation regenerated (if schema changed)

---

*Generated by `/proof-report` skill. Use this content in the PR description.*
```

Write to file:

```bash
Write(file_path="${REPORT_PATH}", content=report_content)
```

## Step 6: Present Result

```
=== PROOF REPORT GENERATED ===

Location: ${REPORT_PATH}

This file is gitignored and won't be committed.

Use the content in your PR description:
1. Copy relevant sections to the PR template
2. Include test output and API verification
3. Reference this report for detailed evidence

To view: cat ${REPORT_PATH}
```

**Offer to display:**

```
AskUserQuestion(
  header: "View Report",
  question: "Would you like to see the generated report?",
  options: [
    { label: "Yes", description: "Display the full report" },
    { label: "No", description: "Done" }
  ]
)
```

If "Yes", display the report content.

</process>

<report_template>
The report follows this structure:

1. **Summary** — Brief description of what was done
2. **Files Changed** — List of modified files
3. **Commits** — Recent commit history
4. **Test Results** — Table of tests with PASS/FAIL status
5. **API Verification** — Mitmproxy output showing correct parameters
6. **Checklist** — Production readiness confirmation

This format aligns with the PR template requirements in [CONTRIBUTING.md](CONTRIBUTING.md).
</report_template>

<success_criteria>

- [ ] Issue number determined
- [ ] Test results gathered
- [ ] API verification status captured
- [ ] Implementation summary written
- [ ] Report file created at `.dev/<ISSUE_NUMBER>_PROOF_REPORT.md`
- [ ] Report displayed or path provided to user
</success_criteria>

<tips>
- Run `/ready` first to ensure all checks pass before generating the report
- The report is gitignored, so you can include detailed output without worrying about committing it
- Copy the most relevant sections to the PR description
- Keep API verification snippets focused on the specific parameters being tested
</tips>
